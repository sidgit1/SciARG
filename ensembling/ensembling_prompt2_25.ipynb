{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e5323d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (4.9.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: sacremoses in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from transformers) (4.61.1)\n",
      "Requirement already satisfied: packaging in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from transformers) (1.20.2)\n",
      "Requirement already satisfied: filelock in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from huggingface-hub==0.0.12->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: joblib in /home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages (from sacremoses->transformers) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f8abb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#change sheetname\n",
    "# train_df=pd.read_excel('../data/data.xlsx', sheet_name=0)\n",
    "# test_df=pd.read_excel('../../data/data.xlsx', sheet_name=2)\n",
    "test_df=pd.read_excel('../../data/connor.xlsx', sheet_name=0)\n",
    "\n",
    "val_df=pd.read_excel('../../data/data.xlsx', sheet_name=1)\n",
    "# noisy_train_df=pd.read_excel('../../data/noisy_train_cot_0.xlsx', sheet_name=0)\n",
    "\n",
    "bad_chars = [';', ':', \"(\", \")\", \"-\", \"'\", \"\\\"\", \"_\", \".\", \",\", \" \"]\n",
    "\n",
    "def components(df):\n",
    "    statements = list(df['statements'])\n",
    "    labels = list(df['labels'])\n",
    "    genes = list(df['target_genes'])\n",
    "    return statements, labels, genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "475d02e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-193753be380d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ff6b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target_genes</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>statements</th>\n",
       "      <th>review_label</th>\n",
       "      <th>label</th>\n",
       "      <th>Remarks</th>\n",
       "      <th>labels</th>\n",
       "      <th>connor_notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1436</td>\n",
       "      <td>msbA</td>\n",
       "      <td>4979069</td>\n",
       "      <td>coli conclude that the conformational transiti...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ABC transporter</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>343</td>\n",
       "      <td>CpxR</td>\n",
       "      <td>5063474</td>\n",
       "      <td>The results showed that, apart from the previo...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1382</td>\n",
       "      <td>mphI</td>\n",
       "      <td>5760710</td>\n",
       "      <td>MphI shares high sequence identity (94%) to ho...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Note that the actual conclusion of the linked ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187</td>\n",
       "      <td>cpxA</td>\n",
       "      <td>3319533</td>\n",
       "      <td>The disruption at cpxAR operon was confirmed w...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>plasmid</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854</td>\n",
       "      <td>sdiA</td>\n",
       "      <td>2812512</td>\n",
       "      <td>It was recently discovered that S . Typhimuriu...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 target_genes    pmcid  \\\n",
       "0        1436         msbA  4979069   \n",
       "1         343         CpxR  5063474   \n",
       "2        1382         mphI  5760710   \n",
       "3         187         cpxA  3319533   \n",
       "4        1854         sdiA  2812512   \n",
       "\n",
       "                                          statements  review_label  label  \\\n",
       "0  coli conclude that the conformational transiti...          -1.0      1   \n",
       "1  The results showed that, apart from the previo...          -1.0     -1   \n",
       "2  MphI shares high sequence identity (94%) to ho...           1.0      1   \n",
       "3  The disruption at cpxAR operon was confirmed w...          -1.0      1   \n",
       "4  It was recently discovered that S . Typhimuriu...          -1.0     -1   \n",
       "\n",
       "            Remarks  labels                                       connor_notes  \n",
       "0  ABC transporter        0                                                NaN  \n",
       "1               NaN       0                                                NaN  \n",
       "2               NaN       0  Note that the actual conclusion of the linked ...  \n",
       "3           plasmid       0                                                NaN  \n",
       "4               NaN       0                                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1fde700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_genes</th>\n",
       "      <th>statements</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDM-1</td>\n",
       "      <td>5% in Indian and Pakistan hospitals . In addit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>otrC</td>\n",
       "      <td>Additionally, the significantly enhanced vanco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FosB</td>\n",
       "      <td>Thus, the P1 space group appears to be the res...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CpxR</td>\n",
       "      <td>In Klebsiella pneumoniae, CpxR is involved in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mfd</td>\n",
       "      <td>3) . Thus, the reduced spontaneous mutation ra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_genes                                         statements  labels\n",
       "0        NDM-1  5% in Indian and Pakistan hospitals . In addit...       1\n",
       "1         otrC  Additionally, the significantly enhanced vanco...       1\n",
       "2         FosB  Thus, the P1 space group appears to be the res...       1\n",
       "3         CpxR  In Klebsiella pneumoniae, CpxR is involved in ...       1\n",
       "4          mfd  3) . Thus, the reduced spontaneous mutation ra...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ad7672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_statements, train_labels, train_genes=components(train_df)\n",
    "test_statements, test_labels, test_genes=components(test_df)\n",
    "val_statements, val_labels, val_genes=components(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "15a37517",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_train_statements, noisy_train_labels, noisy_train_genes=components(noisy_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf306eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "Device name: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa9ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ae6cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    \n",
    "set_seed(42)    # Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d53d765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['antibiotic', 'resistant']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_encoding_1=tokenizer.tokenize(\" is \")\n",
    "print(prompt_template_encoding_1)\n",
    "prompt_template_encoding_2=tokenizer.tokenize(\" antibiotic resistant \")\n",
    "prompt_template_encoding_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cff1873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  4 18:17:42 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.66       Driver Version: 450.66       CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     On   | 00000000:3D:00.0 Off |                  Off |\n",
      "| 33%   31C    P8    34W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000     On   | 00000000:3F:00.0 Off |                  Off |\n",
      "| 33%   33C    P8    23W / 260W |   1920MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000     On   | 00000000:40:00.0 Off |                  Off |\n",
      "| 33%   33C    P8    23W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 8000     On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 33%   31C    P8    32W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A     45260      C   ...onda3/envs/sid/bin/python     1917MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d31c4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kill -9 26647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c157868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare mask keywords\n",
    "\n",
    "bad_chars = [';', ':', \"(\", \")\", \"-\", \"'\", \"\\\"\", \"_\", \".\", \",\", \" \"]\n",
    "\n",
    "rule1=['resistan', 'efflux']\n",
    "\n",
    "rule2=[\"beta-lactamase\", \"beta lactamase\",  \"streptogramin inactivation enzyme\", \n",
    "\"fosfomycin inactivation enzyme\",\n",
    "\"tetracycline inactivation enzyme \", #AMR gene\n",
    "\"macrolide inactivation enzyme\",\n",
    "\"rifampin inactivation enzyme\",\n",
    "\"aminoglycoside acetyltransferase\", #\"AAC\",\n",
    "\"chloramphenicol phosphotransferase\",\n",
    "\"aminoglycoside phosphotransferase\", #\"APH\",\n",
    "\"chloramphenicol acetyltransferase\", #\"CAT\", \n",
    "\"aminoglycoside nucleotidyltransferase\", #\"ANT\",\n",
    "\"lincosamide nucleotidyltransferase\", #\"LNU\" \n",
    "\"streptothricin acetyltransferase\", #\"SAT\", \n",
    "\"fusidic acid inactivation enzyme\",\n",
    "\"Edeine acetyltransferase\", \n",
    "\"viomycin phosphotransferase\", \n",
    "\"ciprofloxacin phosphotransferase\",\n",
    "\"Bah amidohydrolase\",\n",
    "\"MDR\",\n",
    "\"MRSA\"]\n",
    "\n",
    "rule3=['bla', 'mec']\n",
    "\n",
    "rule4=['MIC', 'increase', 'fold']\n",
    "\n",
    "antibiotics_df=pd.read_excel('../../data/antibiotics.xlsx', sheet_name=0)\n",
    "temp_keywords=list(antibiotics_df['antibiotics'])\n",
    "temp_keywords = [y for x in [temp_keywords, rule1] for y in x]\n",
    "temp_keywords = [y for x in [temp_keywords, rule2] for y in x]\n",
    "temp_keywords = [y for x in [temp_keywords, rule3] for y in x]\n",
    "temp_keywords = [y for x in [temp_keywords, rule4] for y in x]\n",
    "mask_keywords=[]\n",
    "for i in range(len(temp_keywords)):\n",
    "    keywords=temp_keywords[i].replace(\"-\", \" \").split()\n",
    "#     for j in range(len(keywords)):\n",
    "#         filtered_word=''.join(k for k in keywords[j] if not k in bad_chars)\n",
    "    mask_keywords = [y for x in [mask_keywords, keywords] for y in x]\n",
    "mask_keywords=[i for i in mask_keywords if len(i)>2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c846c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_keywords=random.sample(mask_keywords, int(len(mask_keywords)*0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "398274e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_for_bert(statements, labels, genes):\n",
    "    pretokenized_encodings=[]\n",
    "    mask_indices=[]\n",
    "    prompt_encodings=[]\n",
    "    all_masks=[]\n",
    "    for idx in range(len(statements)):\n",
    "        sub_tokens=tokenizer.tokenize(statements[idx], add_special_tokens=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "        gene_encoding=tokenizer.tokenize(genes[idx])\n",
    "        prompt=[]\n",
    "        prompt = [y for x in [prompt, gene_encoding] for y in x]\n",
    "        prompt = [y for x in [prompt, prompt_template_encoding_1] for y in x]\n",
    "        if(labels[idx]==1):\n",
    "            prompt.append('possibly')\n",
    "        else:\n",
    "            prompt.append('not')\n",
    "        prompt = [y for x in [prompt, prompt_template_encoding_2] for y in x]\n",
    "#         prompt.append('[SEP]')\n",
    "        if(len(sub_tokens)+len(prompt)+1>512):\n",
    "            sub_tokens=sub_tokens[:(512-len(prompt)-2)]\n",
    "            sub_tokens.append('[SEP]')\n",
    "        sub_tokens = [y for x in [sub_tokens, prompt] for y in x]\n",
    "        mask_index=len(sub_tokens)-3\n",
    "#         for idx in range(512-len(sub_tokens)):\n",
    "#             sub_tokens.append('[PAD]')\n",
    "#         pretokenized_encodings.append(sub_tokens)\n",
    "        mask_indices.append(mask_index)\n",
    "        prompt_encodings.append(prompt)\n",
    "        \n",
    "      ############################################################  \n",
    "        \n",
    "        #sub_tokens doesn't have [SEP] at the end\n",
    "        #Exclude CLS SEP and prompt\n",
    "        sub_tokens=sub_tokens[1:-(len(prompt)+1)]\n",
    "        input_statement=tokenizer.convert_tokens_to_string(sub_tokens)\n",
    "        tokens=input_statement.split()\n",
    "        masks=[0]\n",
    "        for token in tokens:\n",
    "            sub_tokens=tokenizer.tokenize(token) #{'prepare_for_tokenization':True})\n",
    "            word=tokenizer.convert_tokens_to_string(sub_tokens)\n",
    "            #bla+target_gene\n",
    "            filtered_gene=''.join(i for i in genes[idx] if not i in bad_chars)\n",
    "            filtered_word=''.join(i for i in word if not i in bad_chars)\n",
    "            if filtered_gene.lower() in filtered_word.lower():\n",
    "                temp_list=[0]*len(sub_tokens)\n",
    "            else:\n",
    "                flag=0\n",
    "                for keyword in mask_keywords:\n",
    "                    filtered_keyword=''.join(i for i in keyword if not i in bad_chars)\n",
    "                    if filtered_keyword.lower() in filtered_word.lower():\n",
    "                        flag=1\n",
    "                        temp_list=[1]*len(sub_tokens)\n",
    "                        break\n",
    "                if flag==0:\n",
    "                    temp_list=[0]*len(sub_tokens)\n",
    "            masks = [y for x in [masks, temp_list] for y in x]\n",
    "#         if(len(masks)>512):\n",
    "#             del masks[512:]\n",
    "#         elif (len(masks)==512 and masks[511]==1):\n",
    "#             masks[511]=0\n",
    "#         else:\n",
    "#             temp_list=[0]*(512-len(masks))\n",
    "#             masks = [y for x in [masks, temp_list] for y in x]\n",
    "        # print(masks)\n",
    "        all_masks.append(masks)\n",
    "        \n",
    "    return prompt_encodings, mask_indices, all_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67372bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_for_bert_dev(statements, labels, genes):\n",
    "    pretokenized_encodings=[]\n",
    "    mask_indices=[]\n",
    "    prompt_encodings=[]\n",
    "    all_masks=[]\n",
    "    for idx in range(len(statements)):\n",
    "        sub_tokens=tokenizer.tokenize(statements[idx], add_special_tokens=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "        gene_encoding=tokenizer.tokenize(genes[idx])\n",
    "        prompt=[]\n",
    "        prompt = [y for x in [prompt, gene_encoding] for y in x]\n",
    "        prompt = [y for x in [prompt, prompt_template_encoding_1] for y in x]\n",
    "        if(labels[idx]==1):\n",
    "            prompt.append('possibly')\n",
    "        else:\n",
    "            prompt.append('not')\n",
    "        prompt = [y for x in [prompt, prompt_template_encoding_2] for y in x]\n",
    "#         prompt.append('[SEP]')\n",
    "        if(len(sub_tokens)+len(prompt)+1>512):\n",
    "            sub_tokens=sub_tokens[:(512-len(prompt)-2)]\n",
    "            sub_tokens.append('[SEP]')\n",
    "        sub_tokens = [y for x in [sub_tokens, prompt] for y in x]\n",
    "        mask_index=len(sub_tokens)-3\n",
    "#         for idx in range(512-len(sub_tokens)):\n",
    "#             sub_tokens.append('[PAD]')\n",
    "#         pretokenized_encodings.append(sub_tokens)\n",
    "        mask_indices.append(mask_index)\n",
    "        prompt_encodings.append(prompt)\n",
    "        \n",
    "#       ############################################################  \n",
    "        \n",
    "#         #sub_tokens doesn't have [SEP] at the end\n",
    "#         #Exclude CLS SEP and prompt\n",
    "#         sub_tokens=sub_tokens[1:-(len(prompt)+1)]\n",
    "#         input_statement=tokenizer.convert_tokens_to_string(sub_tokens)\n",
    "#         tokens=input_statement.split()\n",
    "#         masks=[0]\n",
    "#         for token in tokens:\n",
    "#             sub_tokens=tokenizer.tokenize(token) #{'prepare_for_tokenization':True})\n",
    "#             word=tokenizer.convert_tokens_to_string(sub_tokens)\n",
    "#             #bla+target_gene\n",
    "#             filtered_gene=''.join(i for i in genes[idx] if not i in bad_chars)\n",
    "#             filtered_word=''.join(i for i in word if not i in bad_chars)\n",
    "#             if filtered_gene.lower() in filtered_word.lower():\n",
    "#                 temp_list=[0]*len(sub_tokens)\n",
    "#             else:\n",
    "#                 flag=0\n",
    "#                 for keyword in mask_keywords:\n",
    "#                     filtered_keyword=''.join(i for i in keyword if not i in bad_chars)\n",
    "#                     if filtered_keyword.lower() in filtered_word.lower():\n",
    "#                         flag=1\n",
    "#                         temp_list=[1]*len(sub_tokens)\n",
    "#                         break\n",
    "#                 if flag==0:\n",
    "#                     temp_list=[0]*len(sub_tokens)\n",
    "#             masks = [y for x in [masks, temp_list] for y in x]\n",
    "# #         if(len(masks)>512):\n",
    "# #             del masks[512:]\n",
    "# #         elif (len(masks)==512 and masks[511]==1):\n",
    "# #             masks[511]=0\n",
    "# #         else:\n",
    "# #             temp_list=[0]*(512-len(masks))\n",
    "# #             masks = [y for x in [masks, temp_list] for y in x]\n",
    "#         # print(masks)\n",
    "#         all_masks.append(masks)\n",
    "        \n",
    "    return prompt_encodings, mask_indices#, all_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19863eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #prompt, label_mask, rule_mask\n",
    "# train_pretokenized_encodings, train_mask_indices, train_rule_masks=preprocessing_for_bert(train_statements, train_labels, train_genes)\n",
    "# test_pretokenized_encodings, test_mask_indices, test_rule_masks=preprocessing_for_bert(test_statements, test_labels, test_genes)\n",
    "\n",
    "# train_pretokenized_encodings, mask_indices=preprocessing_for_bert(statements, labels, genes)\n",
    "val_pretokenized_encodings, val_mask_indices=preprocessing_for_bert_dev(val_statements, val_labels, val_genes)\n",
    "test_pretokenized_encodings, test_mask_indices=preprocessing_for_bert_dev(test_statements, test_labels, test_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f07a9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_train_pretokenized_encodings, noisy_train_mask_indices=preprocessing_for_bert_dev(noisy_train_statements, noisy_train_labels, noisy_train_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5478cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt, label_mask, rule_mask\n",
    "# train_pretokenized_strings=[]\n",
    "# for idx in range(len(train_pretokenized_encodings)):\n",
    "#     train_pretokenized_strings.append(tokenizer.convert_tokens_to_string(train_pretokenized_encodings[idx]))\n",
    "\n",
    "val_pretokenized_strings=[]\n",
    "for idx in range(len(val_pretokenized_encodings)):\n",
    "    val_pretokenized_strings.append(tokenizer.convert_tokens_to_string(val_pretokenized_encodings[idx]))\n",
    "\n",
    "# train_pretokenized_strings=pretokenized_strings[:int(len(pretokenized_strings) * .90)]\n",
    "# val_pretokenized_strings=pretokenized_strings[int(len(pretokenized_strings) * .90):]\n",
    "# train_mask_indices=mask_indices[:int(len(mask_indices) * .90)]\n",
    "# val_mask_indices=mask_indices[int(len(mask_indices) * .90):]\n",
    "# train_rule_masks=rule_masks[:int(len(rule_masks) * .90)]\n",
    "# val_rule_masks=rule_masks[int(len(rule_masks) * .90):]\n",
    "\n",
    "test_pretokenized_strings=[]\n",
    "for idx in range(len(test_pretokenized_encodings)):\n",
    "    test_pretokenized_strings.append(tokenizer.convert_tokens_to_string(test_pretokenized_encodings[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e9118bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_train_pretokenized_strings=[]\n",
    "for idx in range(len(noisy_train_pretokenized_encodings)):\n",
    "    noisy_train_pretokenized_strings.append(tokenizer.convert_tokens_to_string(noisy_train_pretokenized_encodings[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2dd3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_statements=statements[:int(len(statements) * .90)]\n",
    "# val_statements=statements[int(len(statements) * .90):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4fe323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(statements, prompts, mask_ind, rule_masks):\n",
    "    inputs = tokenizer(\n",
    "        statements,prompts,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        add_special_tokens=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "#     inputs['labels'] = inputs['input_ids'].clone()\n",
    "    inputs['labels']=torch.ones(len(inputs['input_ids']),512, dtype=int)    \n",
    "    inputs['mask_idx']=torch.zeros(len(inputs['input_ids']),1, dtype=int)\n",
    "    for idx in range(len(inputs['input_ids'])):\n",
    "        inputs['labels'][idx][mask_ind[idx]]=inputs['input_ids'][idx][mask_ind[idx]]\n",
    "        inputs['input_ids'][idx][mask_ind[idx]]=tokenizer.mask_token_id\n",
    "        #################\n",
    "        ## MLM ##\n",
    "        rule_mask=rule_masks[idx]\n",
    "        for i in range(len(rule_mask)):\n",
    "            if rule_mask[i]==1:\n",
    "                inputs['labels'][idx][i]=inputs['input_ids'][idx][i]\n",
    "                inputs['input_ids'][idx][i]=tokenizer.mask_token_id\n",
    "        #################\n",
    "        inputs['mask_idx'][idx][0]=mask_ind[idx]\n",
    "#     inputs['labels'][inputs['labels'] != tokenizer.mask_token_id] = 1 # only calculate loss on masked tokens\n",
    "#     inputs['labels']=[1 for i in inputs['labels'][idx] if i!=tokenizer.mask_token_id]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e9bb6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_normal(statements, prompts, mask_ind):\n",
    "    inputs = tokenizer(\n",
    "        statements,prompts,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        add_special_tokens=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "#     inputs['labels'] = inputs['input_ids'].clone()\n",
    "    inputs['labels']=torch.ones(len(inputs['input_ids']),512, dtype=int)    \n",
    "    inputs['mask_idx']=torch.zeros(len(inputs['input_ids']),1, dtype=int)\n",
    "    for idx in range(len(inputs['input_ids'])):\n",
    "        inputs['labels'][idx][mask_ind[idx]]=inputs['input_ids'][idx][mask_ind[idx]]\n",
    "        inputs['input_ids'][idx][mask_ind[idx]]=tokenizer.mask_token_id\n",
    "        #################\n",
    "        ## MLM ##\n",
    "#         rule_mask=rule_masks[idx]\n",
    "#         for i in range(len(rule_mask)):\n",
    "#             if rule_mask[i]==1:\n",
    "#                 inputs['labels'][idx][i]=inputs['input_ids'][idx][i]\n",
    "#                 inputs['input_ids'][idx][i]=tokenizer.mask_token_id\n",
    "        #################\n",
    "        inputs['mask_idx'][idx][0]=mask_ind[idx]\n",
    "#     inputs['labels'][inputs['labels'] != tokenizer.mask_token_id] = 1 # only calculate loss on masked tokens\n",
    "#     inputs['labels']=[1 for i in inputs['labels'][idx] if i!=tokenizer.mask_token_id]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "084cead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_ids = self.encodings['input_ids'][index]\n",
    "        labels = self.encodings['labels'][index]\n",
    "        attention_mask = self.encodings['attention_mask'][index]\n",
    "        token_type_ids = self.encodings['token_type_ids'][index]\n",
    "        mask_idx = self.encodings['mask_idx'][index]\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'labels': labels,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'mask_idx': mask_idx\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54914c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq_BookDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_ids = self.encodings['input_ids'][index]\n",
    "        labels = self.encodings['labels'][index]\n",
    "        attention_mask = self.encodings['attention_mask'][index]\n",
    "        token_type_ids = self.encodings['token_type_ids'][index]\n",
    "        mask_idx = self.encodings['mask_idx'][index]\n",
    "        seq_labels = self.encodings['seq_labels'][index]\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'labels': labels,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'mask_idx': mask_idx,\n",
    "            'seq_labels': seq_labels \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eecbb29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_inputs_MLM=tokenize(train_statements, train_pretokenized_strings, train_mask_indices, train_rule_masks)\n",
    "# val_inputs=tokenize(val_statements, val_pretokenized_strings, val_mask_indices, val_rule_masks)\n",
    "# test_inputs=tokenize(test_statements, test_pretokenized_strings, test_mask_indices, test_rule_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "569f4f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_inputs_normal=tokenize_normal(train_statements, train_pretokenized_strings, train_mask_indices)\n",
    "val_inputs_normal=tokenize_normal(val_statements, val_pretokenized_strings, val_mask_indices)\n",
    "test_inputs_normal=tokenize_normal(test_statements, test_pretokenized_strings, test_mask_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6d1f42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_train_inputs_normal=tokenize_normal(noisy_train_statements, noisy_train_pretokenized_strings, noisy_train_mask_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca4bddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# ftr = open('final_train_inputs_new_prompt2_MLM_50.txt', 'wb')\n",
    "# pickle.dump(train_inputs, ftr)\n",
    "# ftr.close()\n",
    "# # fv = open('val_inputs_prompt1_MLM.txt', 'wb')\n",
    "# # pickle.dump(val_inputs, fv)\n",
    "# # fv.close()\n",
    "# # ft = open('test_inputs_prompt1_MLM.txt', 'wb')\n",
    "# # pickle.dump(test_inputs, ft)\n",
    "# # ft.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07767a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('final_train_inputs_new_prompt2_MLM_50.txt', 'rb') as handle:\n",
    "#     data = handle.read()\n",
    "# train_inputs_MLM = pickle.loads(data)\n",
    "\n",
    "# # with open('val_inputs_prompt1_MLM.txt', 'rb') as handle:\n",
    "# #     data = handle.read()\n",
    "# # val_inputs_MLM = pickle.loads(data)\n",
    "\n",
    "# # with open('test_inputs_prompt1_MLM.txt', 'rb') as handle:\n",
    "# #     data = handle.read()\n",
    "# # test_inputs_MLM = pickle.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa110d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################\n",
    "# train_dataset=BookDataset(train_inputs)\n",
    "# ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5294204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## create labels for sequential optimization\n",
    "# train_inputs_MLM['seq_labels']=train_inputs_MLM['labels']\n",
    "# for i in range(len(train_inputs_MLM['seq_labels'])):\n",
    "#     train_inputs_MLM['seq_labels'][i][train_inputs_MLM['mask_idx'][i][0]]=tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01d32651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset_normal=BookDataset(train_inputs_normal)\n",
    "val_dataset=BookDataset(val_inputs_normal)\n",
    "test_dataset=BookDataset(test_inputs_normal)\n",
    "# train_dataset=BookDataset(train_inputs_MLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "530928b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_train_dataset=BookDataset(noisy_train_inputs_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38ba1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset=Seq_BookDataset(train_inputs_MLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd2e05f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2084\n",
      "6553\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_tokens_to_ids(\"not\"))\n",
    "print(tokenizer.convert_tokens_to_ids(\"possibly\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9215d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8551378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, train_dataloader):\n",
    "\n",
    "#     set_seed(42)\n",
    "#     optimizer = AdamW(model.parameters(), lr=2e-05)\n",
    "#     model.train()\n",
    "\n",
    "#     # Tracking variables\n",
    "#     train_loss = []\n",
    "#     tp=0\n",
    "#     tn=0\n",
    "#     fp=0\n",
    "#     fn=0\n",
    "#     unk_pos=0\n",
    "#     unk_neg=0\n",
    "#     # for epoch in range(epochs):\n",
    "#     #     loop = tqdm(train_dataloader)\n",
    "#     for batch in train_dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         labels = batch['labels'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#         loss = outputs.loss   \n",
    "#         train_loss.append(loss.item())\n",
    "#         b_probabilities = F.softmax(outputs.logits, dim=-1)\n",
    "#         # Get the predictions\n",
    "#         preds = torch.argmax(b_probabilities, dim=2)\n",
    "#     #     print(\"preds: \", preds[0])\n",
    "#     #     print(\"labels: \", labels[0])\n",
    "#         # Calculate the accuracy rate\n",
    "#         for i in range(len(batch['input_ids'])):\n",
    "#             pred=preds[i][batch['mask_idx'][i][0]]\n",
    "#             label=labels[i][batch['mask_idx'][i][0]]\n",
    "# #             print(\"pred: \", tokenizer.convert_ids_to_tokens(pred.item()))\n",
    "# #             print(\"label: \", tokenizer.convert_ids_to_tokens(label.item()))\n",
    "#             if pred == 6553 and label == 6553: \n",
    "#                 tp+=1\n",
    "#             elif pred == 6553 and label == 2084:\n",
    "#                 fp+=1\n",
    "#             elif pred == 2084 and label == 2084:\n",
    "#                 tn+=1\n",
    "#             elif pred == 2084 and label == 6553:\n",
    "#                 fn+=1\n",
    "#             elif label == 6553:\n",
    "#                 unk_pos+=1\n",
    "#             else:\n",
    "#                 unk_neg+=1\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "\n",
    "# #     train_loss = np.mean(train_loss)\n",
    "# #     #balanced accuracy = (tpr+tnr)/2\n",
    "# #     train_precision=tp/(tp+fp)\n",
    "# #     train_recall=tp/(tp+fn+unk_pos)\n",
    "# #     train_f1=2*train_precision*train_recall/(train_precision+train_recall)\n",
    "# #     train_balanced_accuracy = (train_recall+(tn/(tn+fp+unk_neg)))/2\n",
    "# #     train_accuracy = (tp+tn)/(tp+tn+fp+fn+unk_pos+unk_neg)\n",
    "#     train_total_not_predicted = unk_pos+unk_neg\n",
    "    \n",
    "    \n",
    "#     train_loss = np.mean(train_loss)\n",
    "# #     train_accuracy = np.mean(train_accuracy)\n",
    "    \n",
    "#     beta=0.5\n",
    "#     train_precision_pos=tp/(tp+fp)\n",
    "#     train_recall_pos=tp/(tp+fn+unk_pos)\n",
    "#     train_f1_pos=2*train_precision_pos*train_recall_pos/(train_precision_pos+train_recall_pos)\n",
    "# #     train_balanced_accuracy = (train_recall+(tn/(tn+fp)))/2\n",
    "#     train_precision_neg=tn/(tn+fn)\n",
    "#     train_recall_neg=tn/(tn+fp+unk_neg)\n",
    "#     train_f1_neg=2*train_precision_neg*train_recall_neg/(train_precision_neg+train_recall_neg)\n",
    "#     train_f1_beta_pos=((1+beta*beta)*train_precision_pos*train_recall_pos)/((1+beta*beta)*train_precision_pos*train_recall_pos+beta*beta*train_precision_pos+train_recall_pos)\n",
    "    \n",
    "#     train_accuracy = (tp+tn)/(tp+tn+fp+fn+unk_pos+unk_neg)\n",
    "# #     train_precision_neg=tn/(tn+fn)\n",
    "# #     train_recall_neg=tn/(tn+fp)\n",
    "# #     train_f1_neg=2*train_precision_pos*train_recall_pos/(train_precision_pos+train_recall_pos)\n",
    "#     train_f1_beta_neg=((1+beta*beta)*train_precision_neg*train_recall_neg)/((1+beta*beta)*train_precision_neg*train_recall_neg+beta*beta*train_precision_neg+train_recall_neg)\n",
    "    \n",
    "#     train_f1_beta=(train_f1_beta_pos+train_f1_beta_neg)/2\n",
    "#     print(f\" check_train_accuracy: {(tp+tn)/(tp+tn+fp+fn)}\")\n",
    "\n",
    "#     return [train_loss, train_accuracy, train_precision_pos, train_recall_pos, train_f1_pos, train_f1_beta_pos,train_precision_neg, train_recall_neg, train_f1_neg, train_f1_beta_neg, train_f1_beta, train_total_not_predicted]\n",
    "\n",
    "# #     return [train_loss, train_precision, train_recall, train_f1, train_balanced_accuracy, train_accuracy, train_total_not_predicted] \n",
    "\n",
    "#     #note total=11264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "265bae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_2(model, train_dataloader):\n",
    "\n",
    "#     set_seed(42)\n",
    "#     optimizer = AdamW(model.parameters(), lr=2e-05)\n",
    "#     model.train()\n",
    "\n",
    "# #     # Tracking variables\n",
    "#     train_loss = []\n",
    "# #     tp=0\n",
    "# #     tn=0\n",
    "# #     fp=0\n",
    "# #     fn=0\n",
    "# #     unk_pos=0\n",
    "# #     unk_neg=0\n",
    "#     # for epoch in range(epochs):\n",
    "#     #     loop = tqdm(train_dataloader)\n",
    "#     for batch in train_dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         labels = batch['seq_labels'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#         loss = outputs.loss   \n",
    "#         train_loss.append(loss.item())\n",
    "\n",
    "# #         # Get the predictions\n",
    "# #         preds = torch.argmax(outputs.logits, dim=2)\n",
    "# #     #     print(\"preds: \", preds[0])\n",
    "# #     #     print(\"labels: \", labels[0])\n",
    "# #         # Calculate the accuracy rate\n",
    "# #         for i in range(len(batch['input_ids'])):\n",
    "# #             pred=preds[i][batch['mask_idx'][i][0]]\n",
    "# #             label=labels[i][batch['mask_idx'][i][0]]\n",
    "# # #             print(\"pred: \", tokenizer.convert_ids_to_tokens(pred.item()))\n",
    "# # #             print(\"label: \", tokenizer.convert_ids_to_tokens(label.item()))\n",
    "# #             if pred == 6228 and label == 6228: \n",
    "# #                 tp+=1\n",
    "# #             elif pred == 6228 and label == 7198:\n",
    "# #                 fp+=1\n",
    "# #             elif pred == 7198 and label == 7198:\n",
    "# #                 tn+=1\n",
    "# #             elif pred == 7198 and label == 6228:\n",
    "# #                 fn+=1\n",
    "# #             elif label == 6228:\n",
    "# #                 unk_pos+=1\n",
    "# #             else:\n",
    "# #                 unk_neg+=1\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     train_loss = np.mean(train_loss)\n",
    "#     return train_loss\n",
    "# #     train_loss = np.mean(train_loss)\n",
    "# #     #balanced accuracy = (tpr+tnr)/2\n",
    "# #     train_precision=tp/(tp+fp)\n",
    "# #     train_recall=tp/(tp+fn+unk_pos)\n",
    "# #     train_f1=2*train_precision*train_recall/(train_precision+train_recall)\n",
    "# #     train_balanced_accuracy = (train_recall+(tn/(tn+fp+unk_neg)))/2\n",
    "# #     train_accuracy = (tp+tn)/(tp+tn+fp+fn+unk_pos+unk_neg)\n",
    "# #     train_total_not_predicted = unk_pos+unk_neg\n",
    "\n",
    "# #     return [train_loss, train_precision, train_recall, train_f1, train_balanced_accuracy, train_accuracy, train_total_not_predicted] \n",
    "\n",
    "#     #note total=11264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "740a0ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify loss function\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# model.to(device)\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "#     val_accuracy = []\n",
    "    val_loss = []\n",
    "    pred_label=[]\n",
    "    tp=0\n",
    "    tn=0\n",
    "    fp=0\n",
    "    fn=0\n",
    "    unk_pos=0\n",
    "    unk_neg=0\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        b_attn_mask = batch['attention_mask'].to(device)\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, attention_mask=b_attn_mask, labels=b_labels)\n",
    "\n",
    "        # Compute loss\n",
    "#         loss=torch.nn.functional.cross_entropy(outputs.logits.view(-1, tokenizer.vocab_size), b_labels.view(-1))\n",
    "        loss=outputs.loss\n",
    "#         loss = loss_fn(outputs.logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "        b_probabilities = F.softmax(outputs.logits, dim=-1)\n",
    "        \n",
    "#         pred = torch.argmax( scores[0][7]).item()\n",
    "#         print(\"predicted token:\", pred, tokenizer.convert_ids_to_tokens([pred])  )\n",
    "#         print(NLLLos( logSoftmax(torch.unsqueeze(scores[0][7], 0)), torch.tensor([pred]))) #the same as F.cross_entropy(scores.view(-1, tokenizer.vocab_size), labels.view(-1))\n",
    "        \n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(outputs.logits, dim=2)\n",
    "        \n",
    "#         print(\"preds: \", preds[0])\n",
    "#         print(\"labels: \", b_labels[0])\n",
    "        # Calculate the accuracy rate\n",
    "#         for i in batch:\n",
    "#         print(b_probabilities.shape)\n",
    "#         print(preds.shape)\n",
    "        for i in range(len(batch['input_ids'])):\n",
    "            \n",
    "            pred=preds[i][batch['mask_idx'][i][0]]\n",
    "            label=b_labels[i][batch['mask_idx'][i][0]]\n",
    "#             print(\"pred: \", preds[i])\n",
    "#             print(\"label: \", labels[i])\n",
    "            prob.append(b_probabilities[i][batch['mask_idx'][i][0]][6553].item())\n",
    "            if pred == 6553 and label == 6553: \n",
    "                tp+=1\n",
    "                pred_label.append(1)\n",
    "#                 prob_tp.append(b_probabilities[i][batch['mask_idx'][i][0]][6553].item())\n",
    "            elif pred == 6553 and label == 2084:\n",
    "                fp+=1\n",
    "                pred_label.append(1)\n",
    "#                 prob_fp.append(b_probabilities[i][batch['mask_idx'][i][0]][6553].item())\n",
    "            elif pred == 2084 and label == 2084:\n",
    "                tn+=1\n",
    "                pred_label.append(0)\n",
    "            elif pred == 2084 and label == 6553:\n",
    "                fn+=1    \n",
    "                pred_label.append(0)\n",
    "            elif label == 6553:\n",
    "                unk_pos+=1\n",
    "                pred_label.append(1)\n",
    "            else:\n",
    "                unk_neg+=1\n",
    "                pred_label.append(0)\n",
    "#         accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "#         val_accuracy.append(accuracy)\n",
    "    val_total_not_predicted = unk_pos+unk_neg\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    beta=0.5\n",
    "    val_loss = np.mean(val_loss)\n",
    "#     val_accuracy = np.mean(val_accuracy)\n",
    "    try:\n",
    "        val_precision_pos=tp/(tp+fp)\n",
    "    except ZeroDivisionError:\n",
    "        val_precision_pos=0\n",
    "    try:\n",
    "        val_recall_pos=tp/(tp+fn)\n",
    "    except ZeroDivisionError:\n",
    "        val_recall_pos=0\n",
    "    try:\n",
    "        val_f1_pos=2*val_precision_pos*val_recall_pos/(val_precision_pos+val_recall_pos)\n",
    "    except ZeroDivisionError:\n",
    "        val_f1_pos=0\n",
    "    try:\n",
    "        val_f1_beta_pos=((1+beta*beta)*val_precision_pos*val_recall_pos)/((1+beta*beta)*val_precision_pos*val_recall_pos+beta*beta*val_precision_pos+val_recall_pos)\n",
    "    except ZeroDivisionError:\n",
    "        val_f1_beta_pos=0\n",
    "#     try:\n",
    "#         val_balanced_accuracy = (val_recall+(tn/(tn+fp)))/2\n",
    "#     except ZeroDivisionError:\n",
    "#         val_balanced_accuracy =0\n",
    "    try:\n",
    "        val_precision_neg=tn/(tn+fn)\n",
    "    except ZeroDivisionError:\n",
    "        val_precision_neg=0\n",
    "    try:\n",
    "        val_recall_neg=tn/(tn+fp)\n",
    "    except ZeroDivisionError:\n",
    "        val_recall_neg=0\n",
    "    try:\n",
    "        val_f1_neg=2*val_precision_neg*val_recall_neg/(val_precision_neg+val_recall_neg)\n",
    "    except ZeroDivisionError:\n",
    "        val_f1_neg=0\n",
    "    try:\n",
    "        val_f1_beta_neg=((1+beta*beta)*val_precision_neg*val_recall_neg)/((1+beta*beta)*val_precision_neg*val_recall_neg+beta*beta*val_precision_neg+val_recall_neg)\n",
    "    except ZeroDivisionError:\n",
    "        val_f1_beta_neg=0\n",
    "    try:\n",
    "        val_f1_beta=(val_f1_beta_pos+val_f1_beta_neg)/2\n",
    "    except ZeroDivisionError:\n",
    "        val_f1_beta=0\n",
    "        \n",
    "    try:\n",
    "        val_accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "    except ZeroDivisionError:\n",
    "        val_accuracy=0\n",
    "        print(\"ZeroDivisionError\")\n",
    "\n",
    "    return [val_loss, val_accuracy, val_precision_pos, val_recall_pos, val_f1_pos, val_f1_beta_pos,val_precision_neg, val_recall_neg, val_f1_neg, val_f1_beta_neg, val_f1_beta, val_total_not_predicted, pred_label] \n",
    "        \n",
    "    \n",
    "#     val_accuracy = np.mean(val_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe5adb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=[8, 12]\n",
    "# learning_rate=[2e-5, 3e-5, 5e-5]\n",
    "epochs=[1,2,3,4,5,6,7,8,9,10]\n",
    "result_train=[[[] for bs in batch_size] for e in epochs]\n",
    "result_val=[[[] for bs in batch_size] for e in epochs]\n",
    "#result_val[e][lr][bs]=[metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f1981",
   "metadata": {},
   "source": [
    "# Rule_mask_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba28b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss, val_accuracy, val_precision_pos, val_recall_pos, val_f1_pos, val_f1_beta_pos, ...negs, f1_beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " check_train_accuracy: 0.9569377990430622\n",
      "batch_size: 8 epoch: 1 result_train: [0.03560936488967764, 0.7031000319590923, 0.9610758801661928, 0.7023010546500479, 0.8115594127966023, 0.47232670607200433, 0.9528444732857452, 0.7038990092681368, 0.8096682290230678, 0.4708711918760021, 0.47159894897400323, 3320] result_val: [0.0038269285450572474, 0.5174825174825175, 0.5091575091575091, 0.972027972027972, 0.6682692307692307, 0.3601036269430052, 0.6923076923076923, 0.06293706293706294, 0.1153846153846154, 0.1875, 0.27380181347150256, 0]\n",
      "0.5174825174825175\n",
      "0.5174825174825175\n",
      "0.5174825174825175\n",
      " check_train_accuracy: 0.9865653738504598\n",
      "batch_size: 8 epoch: 2 result_train: [0.00010844600677617741, 0.9856983061681048, 0.9845442957297642, 0.9873761585170981, 0.9859581937131005, 0.49624941773615827, 0.9886017017177717, 0.9840204538191115, 0.9863057579883079, 0.49690142663482023, 0.4965754221854892, 11] result_val: [0.011628056483437947, 0.4965034965034965, 0.4982456140350877, 0.993006993006993, 0.6635514018691588, 0.35624686402408423, 0.0, 0.0, 0, 0, 0.17812343201204212, 0]\n",
      " check_train_accuracy: 0.996234879436033\n",
      "batch_size: 8 epoch: 3 result_train: [0.003958021519042149, 0.9936081815276446, 0.9956772334293948, 0.9937679769894535, 0.9947216890595009, 0.49882092497232783, 0.9967933301266635, 0.9934483860658357, 0.9951180472188875, 0.4990287521471802, 0.498924838559754, 33] result_val: [0.00972234148131237, 0.541958041958042, 0.5220588235294118, 0.993006993006993, 0.6843373493975904, 0.3657908294693457, 0.9285714285714286, 0.09090909090909091, 0.1656050955414013, 0.24621212121212122, 0.30600147534073346, 0]\n",
      "0.541958041958042\n",
      "0.541958041958042\n",
      "0.541958041958042\n",
      " check_train_accuracy: 0.9974348697394789\n",
      "batch_size: 8 epoch: 4 result_train: [0.0014393186708804196, 0.9941674656439757, 0.9974358974358974, 0.994566954298498, 0.9959993598975837, 0.49921396259103595, 0.9974338412189254, 0.9937679769894535, 0.9955975346193868, 0.49917326184322475, 0.4991936122171303, 41] result_val: [0.009148962691682923, 0.5454545454545454, 0.5247148288973384, 0.965034965034965, 0.6798029556650246, 0.3660477453580902, 0.782608695652174, 0.1258741258741259, 0.21686746987951808, 0.27692307692307694, 0.3214854111405836, 0]\n",
      "0.5454545454545454\n",
      "0.5454545454545454\n",
      " check_train_accuracy: 0.9986360718870346\n",
      "batch_size: 8 epoch: 5 result_train: [0.0006354116197833951, 0.9944870565675935, 0.9985558408215661, 0.9944071588366891, 0.9964771817453963, 0.4994301857113048, 0.9987163029525032, 0.994566954298498, 0.9966373098478783, 0.49947035598497735, 0.4994502708481411, 52] result_val: [0.01314839075506333, 0.5174825174825175, 0.5088967971530249, 1.0, 0.6745283018867925, 0.36074672048435924, 1.0, 0.03496503496503497, 0.06756756756756757, 0.13297872340425534, 0.2468627219443073, 0]\n",
      " check_train_accuracy: 0.9995983290488432\n",
      "batch_size: 8 epoch: 6 result_train: [0.0004011079590755046, 0.9941674656439757, 0.9996786116021211, 0.9940875679130713, 0.9968752503805786, 0.4996385832463256, 0.9995180722891567, 0.9942473633748802, 0.996875751021389, 0.4996145692811717, 0.4996265762637486, 68] result_val: [0.019713391236013247, 0.513986013986014, 0.5070921985815603, 1.0, 0.6729411764705883, 0.3600201409869084, 1.0, 0.027972027972027972, 0.054421768707483, 0.11173184357541902, 0.23587599228116368, 0]\n",
      " check_train_accuracy: 1.0\n",
      "batch_size: 8 epoch: 7 result_train: [0.00028735588827393096, 0.993128795142218, 1.0, 0.9928092042186002, 0.9963916285783018, 0.49963811821471654, 1.0, 0.9934483860658357, 0.9967134268537075, 0.4996704762823295, 0.49965429724852306, 86] result_val: [0.014418616239896487, 0.513986013986014, 0.5070921985815603, 1.0, 0.6729411764705883, 0.3600201409869084, 1.0, 0.027972027972027972, 0.054421768707483, 0.11173184357541902, 0.23587599228116368, 0]\n",
      " check_train_accuracy: 1.0\n",
      "batch_size: 8 epoch: 8 result_train: [0.00025075086407774343, 0.9919303291786513, 1.0, 0.991690635985938, 0.9958279845956355, 0.49958140133951573, 1.0, 0.9921700223713646, 0.9960696238068502, 0.4996057226540498, 0.49959356199678273, 101] result_val: [0.015303861312104507, 0.513986013986014, 0.5070921985815603, 1.0, 0.6729411764705883, 0.3600201409869084, 1.0, 0.027972027972027972, 0.054421768707483, 0.11173184357541902, 0.23587599228116368, 0]\n",
      " check_train_accuracy: 1.0\n",
      "batch_size: 8 epoch: 9 result_train: [0.0001929407843452162, 0.9913710450623202, 1.0, 0.9907318632150847, 0.9953443570396533, 0.4995326952206001, 1.0, 0.9920102269095558, 0.9959890903256859, 0.4995976178979559, 0.499565156559278, 108] result_val: [0.012848368090276008, 0.513986013986014, 0.5070921985815603, 1.0, 0.6729411764705883, 0.3600201409869084, 1.0, 0.027972027972027972, 0.054421768707483, 0.11173184357541902, 0.23587599228116368, 0]\n",
      " check_train_accuracy: 1.0\n",
      "batch_size: 8 epoch: 10 result_train: [0.00016562076280512782, 0.9912911473314158, 1.0, 0.9907318632150847, 0.9953443570396533, 0.4995326952206001, 1.0, 0.9918504314477469, 0.9959085439229844, 0.4995895107934515, 0.49956110300702583, 109] result_val: [0.013573572594785643, 0.513986013986014, 0.5070921985815603, 1.0, 0.6729411764705883, 0.3600201409869084, 1.0, 0.027972027972027972, 0.054421768707483, 0.11173184357541902, 0.23587599228116368, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# print(\"val_loss, val_accuracy, val_precision_pos, val_recall_pos, val_f1_pos, val_f1_beta_pos, ...negs, f1_beta\")\n",
    "# best_model_val_acc=-1\n",
    "# best_model_val_f1=-1\n",
    "# best_model_val_f1_beta=-1\n",
    "# for bs in range(len(batch_size)):\n",
    "#     train_dataloader = torch.utils.data.DataLoader(\n",
    "#         train_dataset_normal,\n",
    "#         batch_size=batch_size[bs],\n",
    "#         #shuffle=True\n",
    "#     )\n",
    "#     val_dataloader = torch.utils.data.DataLoader(\n",
    "#         val_dataset,\n",
    "#         batch_size=batch_size[bs],\n",
    "#     )\n",
    "#     train_dataloader_MLM = torch.utils.data.DataLoader(\n",
    "#                     train_dataset,\n",
    "#                     batch_size=batch_size[bs],\n",
    "#                     #shuffle=True\n",
    "#     )\n",
    "#     torch.cuda.empty_cache() \n",
    "#     model = BertForMaskedLM.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "#     model.to(device)\n",
    "#     for e in range(len(epochs)): \n",
    "#         if e==0 or e==1:\n",
    "#             with open(\"prompt2_25_result_train.txt\", \"wb\") as ft:   #Pickling\n",
    "#                 result_train[e][bs]=train(model, train_dataloader)\n",
    "#                 pickle.dump(result_train, ft)\n",
    "#             ft.close()\n",
    "#             with open(\"prompt2_25_result_val.txt\", \"wb\") as fv:   #Pickling\n",
    "#                 result_val[e][bs]=evaluate(model, val_dataloader)\n",
    "#                 pickle.dump(result_val, fv)\n",
    "#             fv.close()\n",
    "#         else:\n",
    "#             with open(\"prompt2_25_result_train.txt\", \"wb\") as ft:   #Pickling\n",
    "#                 train_mlm_loss=train_2(model, train_dataloader_MLM)\n",
    "#                 result_train[e][bs]=train(model, train_dataloader)\n",
    "#                 result_train[e][bs][0]=(result_train[e][bs][0]+train_mlm_loss)/2\n",
    "#                 pickle.dump(result_train, ft)\n",
    "#             ft.close()\n",
    "#             with open(\"prompt2_25_result_val.txt\", \"wb\") as fv:   #Pickling\n",
    "#                 result_val[e][bs]=evaluate(model, val_dataloader)\n",
    "#                 pickle.dump(result_val, fv)\n",
    "#             fv.close()\n",
    "#         print(f\"batch_size: {batch_size[bs]} epoch: {epochs[e]} result_train: {result_train[e][bs]} result_val: {result_val[e][bs]}\")\n",
    "# #             if(e>1 and result_val[e][lr][bs][5]<result_val[e-1][lr][bs][5]):\n",
    "# #                 print(\"Early stopping\")\n",
    "# #                 break\n",
    "#         if result_val[e][bs][1] > best_model_val_acc:\n",
    "#             best_model_val_acc=result_val[e][bs][1]\n",
    "# #                 !rmdir model_prompt1_MLM\n",
    "#             print(best_model_val_acc)\n",
    "#             model.save_pretrained(save_directory='./prompt2/model/microf1/prompt2_25/saved_model')\n",
    "        \n",
    "#         if result_val[e][bs][4] > best_model_val_f1:\n",
    "#             best_model_val_f1=result_val[e][bs][4]\n",
    "# #                 !rmdir model_prompt1_MLM\n",
    "#             print(best_model_val_acc)\n",
    "#             model.save_pretrained(save_directory='./prompt2/model/f1/prompt2_25/saved_model')\n",
    "#         if result_val[e][bs][10] > best_model_val_f1_beta:\n",
    "#             best_model_val_f1_beta=result_val[e][bs][10]\n",
    "# #                 !rmdir model_prompt1_MLM\n",
    "#             print(best_model_val_acc)\n",
    "#             model.save_pretrained(save_directory='./prompt2/model/f1beta/prompt2_25/saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85e85066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss, val_accuracy, val_precision_pos, val_recall_pos, val_f1_pos, val_f1_beta_pos, ...negs, f1_beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " check_train_accuracy: 0.9774143302180686\n",
      "batch_size: 12 epoch: 1 result_train: [0.05835484872072755, 0.2005433045701502, 0.9821810406272273, 0.220198146372643, 0.35974415872601484, 0.36727078891257997, 0.9716738197424892, 0.1808884627676574, 0.304997979253671, 0.34141633490167694, 0.35434356190712846, 9948] result_val: [0.0033711466130625922, 0.5300353356890459, 0.518796992481203, 0.965034965034965, 0.6748166259168704, 0.3637322087506589, 0.7058823529411765, 0.08571428571428572, 0.15286624203821655, 0.22388059701492538, 0.29380640288279214, 3]\n",
      " check_train_accuracy: 0.9867448586118251\n",
      "batch_size: 12 epoch: 2 result_train: [0.00014697527657251026, 0.981383828699265, 0.9852682145716574, 0.9832214765100671, 0.9842437814924418, 0.49618566843539835, 0.9882315008866678, 0.9795461808884628, 0.9838696733809487, 0.496597537265068, 0.4963916028502332, 68] result_val: [0.005413507924548829, 0.5209790209790209, 0.5109489051094891, 0.9790209790209791, 0.6714628297362111, 0.36101083032490977, 0.75, 0.06293706293706294, 0.11612903225806454, 0.1906779661016949, 0.2758443982133023, 0]\n",
      " check_train_accuracy: 0.9952690241359955\n",
      "batch_size: 12 epoch: 3 result_train: [0.0046570009174878935, 0.991690635985938, 0.9943955164131305, 0.9923298178331735, 0.9933615932176277, 0.4984908810685846, 0.9961451975586251, 0.9910514541387024, 0.993591797500801, 0.49877758476484585, 0.4986342329167152, 45] result_val: [0.01256881514315733, 0.506993006993007, 0.5035211267605634, 1.0, 0.6697892271662763, 0.3585757271815447, 1.0, 0.013986013986013986, 0.027586206896551724, 0.06211180124223602, 0.21034376421189035, 0]\n",
      " check_train_accuracy: 0.9971855902219363\n",
      "batch_size: 12 epoch: 4 result_train: [0.001741477863881185, 0.9908117609459891, 0.9969453376205788, 0.9908916586768935, 0.9939092803333869, 0.49892988751749995, 0.9974259974259975, 0.9907318632150847, 0.9940676607343274, 0.49901806123434533, 0.4989739743759226, 80] result_val: [0.012030752428481506, 0.513986013986014, 0.5071942446043165, 0.986013986013986, 0.6698337292161519, 0.3596938775510204, 0.75, 0.04195804195804196, 0.07947019867549669, 0.14634146341463414, 0.25301767048282725, 0]\n",
      " check_train_accuracy: 0.9980671659821213\n",
      "batch_size: 12 epoch: 5 result_train: [0.0007959131505725781, 0.9901725790987536, 0.9979045776918117, 0.9892937040588047, 0.9935804846734072, 0.49904077125215623, 0.998229518751006, 0.9910514541387024, 0.9946275358832493, 0.4991951062459756, 0.4991179387490659, 99] result_val: [0.009512180023814784, 0.513986013986014, 0.5071942446043165, 0.986013986013986, 0.6698337292161519, 0.3596938775510204, 0.75, 0.04195804195804196, 0.07947019867549669, 0.14634146341463414, 0.25301767048282725, 0]\n",
      " check_train_accuracy: 1.0\n",
      "batch_size: 12 epoch: 6 result_train: [0.0005137828382265465, 0.9948066474912113, 1.0, 0.9953659316075424, 0.9976775846880757, 0.49976732617660746, 1.0, 0.9942473633748802, 0.9971153846153847, 0.4997108712413261, 0.4997390987089668, 65] result_val: [0.0073179388421650655, 0.5699300699300699, 0.5423728813559322, 0.8951048951048951, 0.6754617414248021, 0.37058482918355534, 0.7, 0.24475524475524477, 0.3626943005181347, 0.3378378378378379, 0.3542113335106966, 0]\n",
      "0.5699300699300699\n",
      "0.5699300699300699\n",
      " check_train_accuracy: 1.0\n",
      "batch_size: 12 epoch: 7 result_train: [0.0003154869980907924, 0.9913710450623202, 1.0, 0.9913710450623202, 0.9956668271545499, 0.49956517537926376, 1.0, 0.9913710450623202, 0.9956668271545499, 0.49956517537926376, 0.49956517537926376, 108] result_val: [0.015867382127288925, 0.5, 0.5, 1.0, 0.6666666666666666, 0.35714285714285715, 0, 0.0, 0, 0, 0.17857142857142858, 0]\n",
      " check_train_accuracy: 0.9999193418293273\n",
      "batch_size: 12 epoch: 8 result_train: [0.00026634348734060444, 0.9904921700223713, 0.9998385794995964, 0.9897730904442313, 0.9947803742070184, 0.49945168365372206, 1.0, 0.9912112496005113, 0.9955862290345879, 0.4995570588709028, 0.4995043712623124, 118] result_val: [0.013056949839172086, 0.5, 0.5, 1.0, 0.6666666666666666, 0.35714285714285715, 0, 0.0, 0, 0, 0.17857142857142858, 0]\n",
      " check_train_accuracy: 1.0\n",
      "batch_size: 12 epoch: 9 result_train: [0.0002361352276937661, 0.9894534995206136, 1.0, 0.9896132949824225, 0.9947795357802587, 0.4994757641745302, 1.0, 0.9892937040588047, 0.9946180416097679, 0.49945947690272197, 0.4994676205386261, 132] result_val: [0.014786777433745754, 0.506993006993007, 0.5035211267605634, 1.0, 0.6697892271662763, 0.3585757271815447, 1.0, 0.013986013986013986, 0.027586206896551724, 0.06211180124223602, 0.21034376421189035, 0]\n",
      " check_train_accuracy: 1.0\n",
      "batch_size: 12 epoch: 10 result_train: [0.00022069276497069116, 0.9892138063279002, 1.0, 0.9878555449025248, 0.9938906752411576, 0.4993860669510146, 1.0, 0.9905720677532758, 0.995263707152605, 0.4995245692920111, 0.4994553181215129, 135] result_val: [0.011309989128027572, 0.5034965034965035, 0.5017543859649123, 1.0, 0.6682242990654206, 0.35785785785785784, 1.0, 0.006993006993006993, 0.013888888888888888, 0.03289473684210527, 0.19537629734998155, 0]\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# print(\"val_loss, val_accuracy, val_precision_pos, val_recall_pos, val_f1_pos, val_f1_beta_pos, ...negs, f1_beta\")\n",
    "# best_model_val_acc=0.5454545454545454\n",
    "# best_model_val_f1=0.6798029556650246\n",
    "# best_model_val_f1_beta=0.3214854111405836\n",
    "# for bs in range(len(batch_size)):\n",
    "#     train_dataloader = torch.utils.data.DataLoader(\n",
    "#         train_dataset_normal,\n",
    "#         batch_size=batch_size[bs],\n",
    "#         #shuffle=True\n",
    "#     )\n",
    "#     val_dataloader = torch.utils.data.DataLoader(\n",
    "#         val_dataset,\n",
    "#         batch_size=batch_size[bs],\n",
    "#     )\n",
    "#     train_dataloader_MLM = torch.utils.data.DataLoader(\n",
    "#                     train_dataset,\n",
    "#                     batch_size=batch_size[bs],\n",
    "#                     #shuffle=True\n",
    "#     )\n",
    "#     torch.cuda.empty_cache() \n",
    "#     model = BertForMaskedLM.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "#     model.to(device)\n",
    "#     for e in range(len(epochs)): \n",
    "#         if bs==0:\n",
    "#             continue\n",
    "#         if e==0 or e==1:\n",
    "#             with open(\"prompt2_25_result_train.txt\", \"wb\") as ft:   #Pickling\n",
    "#                 result_train[e][bs]=train(model, train_dataloader)\n",
    "#                 pickle.dump(result_train, ft)\n",
    "#             ft.close()\n",
    "#             with open(\"prompt2_25_result_val.txt\", \"wb\") as fv:   #Pickling\n",
    "#                 result_val[e][bs]=evaluate(model, val_dataloader)\n",
    "#                 pickle.dump(result_val, fv)\n",
    "#             fv.close()\n",
    "#         else:\n",
    "#             with open(\"prompt2_25_result_train.txt\", \"wb\") as ft:   #Pickling\n",
    "#                 train_mlm_loss=train_2(model, train_dataloader_MLM)\n",
    "#                 result_train[e][bs]=train(model, train_dataloader)\n",
    "#                 result_train[e][bs][0]=(result_train[e][bs][0]+train_mlm_loss)/2\n",
    "#                 pickle.dump(result_train, ft)\n",
    "#             ft.close()\n",
    "#             with open(\"prompt2_25_result_val.txt\", \"wb\") as fv:   #Pickling\n",
    "#                 result_val[e][bs]=evaluate(model, val_dataloader)\n",
    "#                 pickle.dump(result_val, fv)\n",
    "#             fv.close()\n",
    "#         print(f\"batch_size: {batch_size[bs]} epoch: {epochs[e]} result_train: {result_train[e][bs]} result_val: {result_val[e][bs]}\")\n",
    "# #             if(e>1 and result_val[e][lr][bs][5]<result_val[e-1][lr][bs][5]):\n",
    "# #                 print(\"Early stopping\")\n",
    "# #                 break\n",
    "#         if result_val[e][bs][1] > best_model_val_acc:\n",
    "#             best_model_val_acc=result_val[e][bs][1]\n",
    "# #                 !rmdir model_prompt1_MLM\n",
    "#             print(best_model_val_acc)\n",
    "#             model.save_pretrained(save_directory='./prompt2/model/microf1/prompt2_25/saved_model')\n",
    "        \n",
    "#         if result_val[e][bs][4] > best_model_val_f1:\n",
    "#             best_model_val_f1=result_val[e][bs][4]\n",
    "# #                 !rmdir model_prompt1_MLM\n",
    "#             print(best_model_val_acc)\n",
    "#             model.save_pretrained(save_directory='./prompt2/model/f1/prompt2_25/saved_model')\n",
    "#         if result_val[e][bs][10] > best_model_val_f1_beta:\n",
    "#             best_model_val_f1_beta=result_val[e][bs][10]\n",
    "# #                 !rmdir model_prompt1_MLM\n",
    "#             print(best_model_val_acc)\n",
    "#             model.save_pretrained(save_directory='./prompt2/model/f1beta/prompt2_25/saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d735f",
   "metadata": {},
   "source": [
    "adjustment for the runtime error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dec191df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5699300699300699, 6, 12)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pick the best model\n",
    "max_result=-1\n",
    "for e in range(len(epochs)):\n",
    "    for bs in range(len(batch_size)):\n",
    "        if(len(result_val[e][bs])!=0):\n",
    "            if(result_val[e][bs][1]>max_result):\n",
    "                max_result=result_val[e][bs][1]\n",
    "                max_e=epochs[e]\n",
    "                max_bs=batch_size[bs]\n",
    "                    \n",
    "max_result,max_e,max_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e361c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=12,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a3f59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "                val_dataset,\n",
    "                batch_size=12,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7b1d602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_train_dataloader = torch.utils.data.DataLoader(\n",
    "                noisy_train_dataset,\n",
    "                batch_size=12,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff1e5b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 12 epoch: 6 result_test: [0.006218405920567682, 0.6299212598425197, 0.601063829787234, 0.9216965742251223, 0.7276239536381197, 0.39247013059183106, 0.7635467980295566, 0.29245283018867924, 0.4229195088676671, 0.3660840812470477, 0.3792771059194394, 0]\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "model = BertForMaskedLM.from_pretrained(\"./prompt2/model/microf1/prompt2_25/saved_model\")\n",
    "model.to(device)\n",
    "max_result_test=evaluate(model, test_dataloader)\n",
    "print(f\"batch_size: {max_bs} epoch: {max_e} result_test: {max_result_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d974f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 1200 epoch: 600 result_test: [0.0073179388421650655, 0.5699300699300699, 0.5423728813559322, 0.8951048951048951, 0.6754617414248021, 0.37058482918355534, 0.7, 0.24475524475524477, 0.3626943005181347, 0.3378378378378379, 0.3542113335106966, 0, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "model = BertForMaskedLM.from_pretrained(\"../../prompt2/prompt2/model/microf1/prompt2_25/saved_model\")\n",
    "model.to(device)\n",
    "prob=[]\n",
    "prob_tp=[]\n",
    "prob_fp=[]\n",
    "max_result_test=evaluate(model, val_dataloader)\n",
    "print(f\"batch_size: {1200} epoch: {600} result_test: {max_result_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecda1b3",
   "metadata": {},
   "source": [
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0417f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9999, 1.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prob_tp.to_list()\n",
    "# prob_tp=torch.stack(prob_tp)\n",
    "# prob_tp\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# # Encode our concatenated data\n",
    "# encoded_seq = [tokenizer.encode(seq, add_special_tokens=True) for seq in statements]\n",
    "\n",
    "# token_len=[]\n",
    "# # Find the maximum length\n",
    "# token_len=[len(sent) for sent in encoded_seq]\n",
    "# # print('Max length: ', max_len)\n",
    "sns.distplot(prob_tp)\n",
    "plt.xlim([0.9999, 1.0])\n",
    "# plt.xlabel('Token count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b80aedc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9999939203262329,\n",
       " 0.999997615814209,\n",
       " 0.9999942779541016,\n",
       " 0.9999498128890991,\n",
       " 0.9999966621398926,\n",
       " 0.9999855756759644,\n",
       " 0.9999344348907471,\n",
       " 0.9999971389770508,\n",
       " 0.9999963045120239,\n",
       " 0.9999983310699463,\n",
       " 0.9999674558639526,\n",
       " 0.9999850988388062,\n",
       " 0.9999829530715942,\n",
       " 0.9951539039611816,\n",
       " 0.999982476234436,\n",
       " 0.9999830722808838,\n",
       " 0.9993053674697876,\n",
       " 0.9999779462814331,\n",
       " 0.9999849796295166,\n",
       " 0.9999912977218628,\n",
       " 0.9999014139175415,\n",
       " 0.9999407529830933,\n",
       " 0.9999902248382568,\n",
       " 0.9999574422836304,\n",
       " 0.9832913279533386,\n",
       " 0.9999929666519165,\n",
       " 0.999901533126831,\n",
       " 0.9999624490737915,\n",
       " 0.9978386759757996,\n",
       " 0.9999943971633911,\n",
       " 0.9999805688858032,\n",
       " 0.9999653100967407,\n",
       " 0.9999860525131226,\n",
       " 0.999970555305481,\n",
       " 0.9999969005584717,\n",
       " 0.9999861717224121,\n",
       " 0.999893069267273,\n",
       " 0.9996309280395508,\n",
       " 0.9999687671661377,\n",
       " 0.999967098236084,\n",
       " 0.9999850988388062,\n",
       " 0.9999901056289673,\n",
       " 0.991899847984314,\n",
       " 0.9999700784683228,\n",
       " 0.9999955892562866,\n",
       " 0.9975456595420837,\n",
       " 0.9993865489959717,\n",
       " 0.9999959468841553,\n",
       " 0.9999575614929199,\n",
       " 0.9999485015869141,\n",
       " 0.9999908208847046,\n",
       " 0.9580956101417542,\n",
       " 0.9982767105102539,\n",
       " 0.9999709129333496,\n",
       " 0.9999672174453735,\n",
       " 0.999983549118042,\n",
       " 0.9975201487541199,\n",
       " 0.9976180195808411,\n",
       " 0.9974530339241028,\n",
       " 0.9996874332427979,\n",
       " 0.9991573095321655,\n",
       " 0.9999711513519287,\n",
       " 0.9990344047546387,\n",
       " 0.9991077780723572,\n",
       " 0.9886723160743713,\n",
       " 0.9599528908729553,\n",
       " 0.962540864944458,\n",
       " 0.9999936819076538,\n",
       " 0.9999698400497437,\n",
       " 0.9974284768104553,\n",
       " 0.9999617338180542,\n",
       " 0.9999874830245972,\n",
       " 0.9899033308029175,\n",
       " 0.9999641180038452,\n",
       " 0.9999773502349854,\n",
       " 0.9999452829360962,\n",
       " 0.9999821186065674,\n",
       " 0.999983549118042,\n",
       " 0.9999697208404541,\n",
       " 0.9997064471244812,\n",
       " 0.9912522435188293,\n",
       " 0.9958821535110474,\n",
       " 0.7664717435836792,\n",
       " 0.8513893485069275,\n",
       " 0.9917156100273132,\n",
       " 0.9999791383743286,\n",
       " 0.9999873638153076,\n",
       " 0.5721126198768616,\n",
       " 0.9999661445617676,\n",
       " 0.9975602626800537,\n",
       " 0.9999604225158691,\n",
       " 0.9999852180480957,\n",
       " 0.9403941035270691,\n",
       " 0.9821507930755615,\n",
       " 0.9999866485595703,\n",
       " 0.9749367237091064,\n",
       " 0.9999270439147949,\n",
       " 0.9999831914901733,\n",
       " 0.9392547607421875,\n",
       " 0.9999638795852661,\n",
       " 0.9999746084213257,\n",
       " 0.9985577464103699,\n",
       " 0.8323268890380859,\n",
       " 0.9999836683273315,\n",
       " 0.9999731779098511,\n",
       " 0.9999734163284302,\n",
       " 0.9999797344207764,\n",
       " 0.999775230884552,\n",
       " 0.9999228715896606,\n",
       " 0.7890108823776245,\n",
       " 0.9999924898147583,\n",
       " 0.9999778270721436,\n",
       " 0.9999634027481079,\n",
       " 0.9996441602706909,\n",
       " 0.999994158744812,\n",
       " 0.9999836683273315,\n",
       " 0.7795394659042358,\n",
       " 0.9700637459754944,\n",
       " 0.9999135732650757,\n",
       " 0.9999617338180542,\n",
       " 0.8489008545875549,\n",
       " 0.9573749303817749,\n",
       " 0.9999912977218628,\n",
       " 0.9999880790710449,\n",
       " 0.9999842643737793,\n",
       " 0.9998546838760376,\n",
       " 0.9752854704856873,\n",
       " 0.9999539852142334]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7af3e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhant/anaconda3/envs/sid/lib/python3.9/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9999, 1.0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prob_tp.to_list()\n",
    "# prob_tp=torch.stack(prob_tp)\n",
    "# prob_tp\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# # Encode our concatenated data\n",
    "# encoded_seq = [tokenizer.encode(seq, add_special_tokens=True) for seq in statements]\n",
    "\n",
    "# token_len=[]\n",
    "# # Find the maximum length\n",
    "# token_len=[len(sent) for sent in encoded_seq]\n",
    "# # print('Max length: ', max_len)\n",
    "sns.distplot(prob_fp)\n",
    "plt.xlim([0.9999, 1.0])\n",
    "# plt.xlabel('Token count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e18542f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9999582767486572,\n",
       " 0.9980798959732056,\n",
       " 0.9999982118606567,\n",
       " 0.9999947547912598,\n",
       " 0.9997144341468811,\n",
       " 0.9999115467071533,\n",
       " 0.9998557567596436,\n",
       " 0.9999873638153076,\n",
       " 0.9999463558197021,\n",
       " 0.9999681711196899,\n",
       " 0.9996938705444336,\n",
       " 0.9999878406524658,\n",
       " 0.9999911785125732,\n",
       " 0.9515300393104553,\n",
       " 0.9999872446060181,\n",
       " 0.969340980052948,\n",
       " 0.9999759197235107,\n",
       " 0.9999780654907227,\n",
       " 0.9999898672103882,\n",
       " 0.9999955892562866,\n",
       " 0.9944759011268616,\n",
       " 0.999980092048645,\n",
       " 0.9927709698677063,\n",
       " 0.999992847442627,\n",
       " 0.9999563694000244,\n",
       " 0.9999850988388062,\n",
       " 0.9999866485595703,\n",
       " 0.9999591112136841,\n",
       " 0.9999693632125854,\n",
       " 0.9999645948410034,\n",
       " 0.999639630317688,\n",
       " 0.9981623291969299,\n",
       " 0.9999853372573853,\n",
       " 0.9342369437217712,\n",
       " 0.999972939491272,\n",
       " 0.9995290040969849,\n",
       " 0.9617842435836792,\n",
       " 0.9231759309768677,\n",
       " 0.9999661445617676,\n",
       " 0.9999712705612183,\n",
       " 0.9880405068397522,\n",
       " 0.999129593372345,\n",
       " 0.9996750354766846,\n",
       " 0.9747108221054077,\n",
       " 0.9987762570381165,\n",
       " 0.8452403545379639,\n",
       " 0.872645914554596,\n",
       " 0.9999843835830688,\n",
       " 0.5557253360748291,\n",
       " 0.999886155128479,\n",
       " 0.8021793961524963,\n",
       " 0.9995381832122803,\n",
       " 0.9997169375419617,\n",
       " 0.9784632325172424,\n",
       " 0.9311732053756714,\n",
       " 0.5239167213439941,\n",
       " 0.999972939491272,\n",
       " 0.9759790301322937,\n",
       " 0.5646010041236877,\n",
       " 0.9999797344207764,\n",
       " 0.7324030995368958,\n",
       " 0.9515300393104553,\n",
       " 0.9999179840087891,\n",
       " 0.9999874830245972,\n",
       " 0.9999866485595703,\n",
       " 0.9999861717224121,\n",
       " 0.9999872446060181,\n",
       " 0.9999873638153076,\n",
       " 0.9925217032432556,\n",
       " 0.9999779462814331,\n",
       " 0.9681747555732727,\n",
       " 0.9999886751174927,\n",
       " 0.9999575614929199,\n",
       " 0.9998879432678223,\n",
       " 0.999972939491272,\n",
       " 0.9998062252998352,\n",
       " 0.7591606974601746,\n",
       " 0.9814847707748413,\n",
       " 0.5584646463394165,\n",
       " 0.999967098236084,\n",
       " 0.9999786615371704,\n",
       " 0.9993752837181091,\n",
       " 0.9986042380332947,\n",
       " 0.9946479201316833,\n",
       " 0.937285304069519,\n",
       " 0.9539347887039185,\n",
       " 0.9999555349349976,\n",
       " 0.999309778213501,\n",
       " 0.8413183093070984,\n",
       " 0.9999490976333618,\n",
       " 0.9999885559082031,\n",
       " 0.5185152292251587,\n",
       " 0.999981164932251,\n",
       " 0.9989462494850159,\n",
       " 0.8111610412597656,\n",
       " 0.9441802501678467,\n",
       " 0.9983382225036621,\n",
       " 0.9999953508377075,\n",
       " 0.9991989731788635,\n",
       " 0.8375951051712036,\n",
       " 0.9988428354263306,\n",
       " 0.9999418258666992,\n",
       " 0.9990731477737427,\n",
       " 0.834950864315033,\n",
       " 0.9999833106994629,\n",
       " 0.9887893199920654,\n",
       " 0.9999819993972778,\n",
       " 0.9950699806213379]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f14811b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "108\n",
      "0.5423728813559322\n",
      "0.8951048951048951\n",
      "0.6754617414248021\n"
     ]
    }
   ],
   "source": [
    "print(len(prob_tp))\n",
    "print(len(prob_fp))\n",
    "tp=len(prob_tp)\n",
    "fp=len(prob_fp)\n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/143\n",
    "f1=2*precision*recall/(precision+recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74ef742d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "6\n",
      "0.7692307692307693\n",
      "0.13986013986013987\n",
      "0.2366863905325444\n"
     ]
    }
   ],
   "source": [
    "tp=0\n",
    "fp=0\n",
    "for i in range(len(prob_tp)):\n",
    "    if prob_tp[i]>0.99999:\n",
    "        tp+=1\n",
    "for i in range(len(prob_fp)):\n",
    "    if prob_fp[i]>0.99999:\n",
    "        fp+=1\n",
    "print(tp)\n",
    "print(fp)\n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/143\n",
    "f1=2*precision*recall/(precision+recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f660bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "model = BertForMaskedLM.from_pretrained(\"../../prompt2/prompt2/model/microf1/prompt2_25/saved_model\")\n",
    "model.to(device)\n",
    "prob=[]\n",
    "prob_tp=[]\n",
    "prob_fp=[]\n",
    "max_result_noisy_train=evaluate(model, noisy_train_dataloader)\n",
    "print(f\"batch_size: {12} epoch: {3} result_test: {max_result_noisy_train[:-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6e58b967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18475"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max_result_noisy_train[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53fca402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"test_labels/prompt2_25_cot1.txt\", \"wb\") as f:   #Pickling\n",
    "    prompt2_labels=max_result_noisy_train[-1]\n",
    "    pickle.dump(prompt2_labels, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "631f6610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max_result_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d9a2423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfe396a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"val_labels/prompt2_25_labels.txt\", \"wb\") as f:   #Pickling\n",
    "    prompt2_labels=max_result_test[-1]\n",
    "    pickle.dump(prompt2_labels, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ec600",
   "metadata": {},
   "source": [
    "# 2000eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbdb5aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 12 epoch: 3 result_test: [0.0060774787033181215, 0.638, 0.6091185410334347, 0.925207756232687, 0.7346041055718476, 0.3953286514637418, 0.7718309859154929, 0.29880043620501634, 0.43081761006289304, 0.3695710817372538, 0.3824498666004978, 0, [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "model = BertForMaskedLM.from_pretrained(\"../../prompt2/prompt2/model/microf1/prompt2_25/saved_model\")\n",
    "model.to(device)\n",
    "prob=[]\n",
    "# prob_tp=[]\n",
    "# prob_fp=[]\n",
    "max_result_test=evaluate(model, test_dataloader)\n",
    "print(f\"batch_size: {12} epoch: {3} result_test: {max_result_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c183687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"2000/test_labels/prompt2_25_labels.txt\", \"wb\") as f:   #Pickling\n",
    "    prompt2_labels=max_result_test[-1]\n",
    "    pickle.dump(prompt2_labels, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ca7e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"2000/test_labels/prompt2_25_prob.txt\", \"wb\") as f:   #Pickling\n",
    "    pickle.dump(prob, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be48bf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 12 epoch: 3 result_test: [0.0065436076951168425, 0.6085, 0.5854214123006833, 0.9492151431209603, 0.7241986615005284, 0.38801238016154604, 0.7745901639344263, 0.20610687022900764, 0.3255813953488372, 0.33298097251585623, 0.36049667633870114, 0, [1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "model = BertForMaskedLM.from_pretrained(\"../../prompt2/prompt2/model/f1/prompt2_50/saved_model\")\n",
    "model.to(device)\n",
    "prob=[]\n",
    "# prob_tp=[]\n",
    "# prob_fp=[]\n",
    "max_result_test=evaluate(model, test_dataloader)\n",
    "print(f\"batch_size: {12} epoch: {3} result_test: {max_result_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "278b6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"2000/test_labels/prompt2_50_labelsf1.txt\", \"wb\") as f:   #Pickling\n",
    "    prompt2_labels=max_result_test[-1]\n",
    "    pickle.dump(prompt2_labels, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "715429d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"2000/test_labels/prompt2_50_probf1.txt\", \"wb\") as f:   #Pickling\n",
    "    pickle.dump(prob, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0de5cf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 12 epoch: 3 result_test: [0.0075587872636724285, 0.5664335664335665, 0.5375494071146245, 0.951048951048951, 0.686868686868687, 0.37057220708446864, 0.7878787878787878, 0.18181818181818182, 0.29545454545454547, 0.32098765432098764, 0.34577993070272817, 0, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "model = BertForMaskedLM.from_pretrained(\"../../prompt2/prompt2/model/f1/prompt2_50/saved_model\")\n",
    "model.to(device)\n",
    "prob=[]\n",
    "# prob_tp=[]\n",
    "# prob_fp=[]\n",
    "max_result_test=evaluate(model, val_dataloader)\n",
    "print(f\"batch_size: {12} epoch: {3} result_test: {max_result_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55cc930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"2000/val_labels/prompt2_50_labelsf1.txt\", \"wb\") as f:   #Pickling\n",
    "    prompt2_labels=max_result_test[-1]\n",
    "    pickle.dump(prompt2_labels, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1744ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"2000/val_labels/prompt2_50_probf1.txt\", \"wb\") as f:   #Pickling\n",
    "    pickle.dump(prob, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f04298",
   "metadata": {},
   "source": [
    "# Connor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8a67eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 12 epoch: 3 result_test: [0.0102823323621932, 0.42, 0.36363636363636365, 0.9411764705882353, 0.5245901639344263, 0.29304029304029305, 0.8333333333333334, 0.15151515151515152, 0.25641025641025644, 0.3048780487804878, 0.2989591709103904, 0, [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "model = BertForMaskedLM.from_pretrained(\"../../prompt2/prompt2/model/f1/prompt2_50/saved_model\")\n",
    "model.to(device)\n",
    "prob=[]\n",
    "# prob_tp=[]\n",
    "# prob_fp=[]\n",
    "max_result_test=evaluate(model, test_dataloader)\n",
    "print(f\"batch_size: {12} epoch: {3} result_test: {max_result_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c52c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
